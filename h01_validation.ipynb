{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt_root_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3531662040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3691674312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3967005302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4911602202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23635194658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pt_root_id\n",
       "0   3531662040\n",
       "1   3691674312\n",
       "2   3967005302\n",
       "3   4911602202\n",
       "4  23635194658"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_df = pd.read_csv('./data/post_ids.csv')\n",
    "cell_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids = cell_df['pt_root_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8380"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cell_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saarthak/microns/core/Branch.py:262: NumbaDeprecationWarning: \u001b[1mThe keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit(parallel=True, fastmath=True, nopython=False)\n",
      "/home/saarthak/microns/core/Branch.py:288: NumbaDeprecationWarning: \u001b[1mThe keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit(parallel=True, fastmath=True, nopython=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "found_keys = set()\n",
    "for fname in os.listdir('./data/trees'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        found_keys.update(trees.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4420"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(found_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir('./data/trees2'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees2',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        found_keys.update(trees.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5760"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(found_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir('./data/trees3'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees3',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        found_keys.update(trees.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir('./data/trees4'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees4',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        found_keys.update(trees.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8350"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(found_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_keys = set(cell_ids) - found_keys\n",
    "missing_cids = list(missing_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_connect_graph(original_graph, desired_nodes):\n",
    "    # Step 1: Initially, identify nodes with multiple parents and nodes to keep\n",
    "    nodes_with_multiple_children = {node for node in original_graph.nodes() if original_graph.out_degree(node) > 1}\n",
    "    nodes_to_keep = desired_nodes.union(nodes_with_multiple_children).union({-1})  # Include root node\n",
    "\n",
    "    # Create a copy of the graph to work on\n",
    "    G = original_graph.copy()\n",
    "\n",
    "    # Step 2: For nodes not in the keep list, redirect parents to children and remove the node\n",
    "    for node in list(G.nodes()):  # List conversion to avoid modification during iteration\n",
    "        if node not in nodes_to_keep:\n",
    "            parents = list(G.predecessors(node))\n",
    "            children = list(G.successors(node))\n",
    "            for parent in parents:\n",
    "                for child in children:\n",
    "                    G.add_edge(parent, child)  # Connect parent directly to child\n",
    "            G.remove_node(node)  # Remove the node after re-connecting\n",
    "\n",
    "    assert -1 in G.nodes(), \"Root node not found in the graph\"\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import navis\n",
    "import cloudvolume as cv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from core.Tree import Tree\n",
    "from core.Branch import BranchSeq\n",
    "\n",
    "def process_chunk(cid, vol, syn_df):\n",
    "    nrns = vol.mesh.get(cid, as_navis=True)\n",
    "    nrns = navis.simplify_mesh(nrns, F=1/3, parallel=True)\n",
    "    print('Simplified')\n",
    "    sks = navis.skeletonize(nrns, parallel=True)\n",
    "    print('Skeletonized')\n",
    "    sks = navis.heal_skeleton(sks, parallel=True)\n",
    "    print('Healed')\n",
    "    sks = navis.prune_twigs(sks, 6000, parallel=True)\n",
    "    trees = {}\n",
    "    branches = {}\n",
    "    for skp in sks:\n",
    "        syn_pos = np.array(syn_df[syn_df['post_pt_root_id'] == skp.id][['x', 'y', 'z']].values) * np.array([8, 8, 33])\n",
    "        pre_cell_ids = np.array(syn_df[syn_df['post_pt_root_id'] == skp.id]['pre_pt_root_id'].values)\n",
    "        syn_ids = np.array(syn_df[syn_df['post_pt_root_id'] == skp.id].index)\n",
    "        \n",
    "        segment_length_dict = {node: navis.segment_length(skp, seg)/1000 for seg in skp.segments for node in seg}\n",
    "        node_ids,_ = skp.snap(syn_pos)\n",
    "        RG = skp.get_graph_nx().reverse()\n",
    "\n",
    "        root_pos = np.array(skp.nodes.iloc[skp.root][['x', 'y', 'z']].values[0])\n",
    "\n",
    "        RG.add_node(-1, pos=root_pos/1000)\n",
    "        for r in skp.root:\n",
    "            RG.add_edge(r, -1)\n",
    "        G = filter_and_connect_graph(RG, set(node_ids))\n",
    "        G.graph['cell_id'] = skp.id\n",
    "        branch_lengths = [segment_length_dict.get(node, 0) for node in list(G.nodes)]\n",
    "        # set node attributes of G with syn_pos, cell_types, and pre_cell_ids\n",
    "        nx.set_node_attributes(G, dict(zip(node_ids, syn_pos/1000)), 'pos')\n",
    "        nx.set_node_attributes(G, dict(zip(node_ids, len(node_ids)*['4P'])), 'cell_type')\n",
    "        nx.set_node_attributes(G, dict(zip(node_ids, pre_cell_ids)), 'pre_cell_id')\n",
    "        nx.set_node_attributes(G, dict(zip(list(G.nodes), branch_lengths)), 'branch_length')\n",
    "\n",
    "        tree = Tree(G.reverse(), root_id=-1)\n",
    "        trees[skp.id] = tree\n",
    "        branches[skp.id] = [BranchSeq(path, tree.graph, (cid, j)) for j, path in enumerate(tree.get_paths())]\n",
    "    \n",
    "    return trees, branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navis.patch_cloudvolume()\n",
    "vol = cv.CloudVolume('precomputed://gs://h01-release/data/20210601/c3', use_https=True, progress=True, parallel=True)\n",
    "\n",
    "syn_df = pd.read_csv('/home/saarthak/microns/data/syn_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees = {}\n",
    "extra_branches = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chunk 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e14e14b8b54792af1315b54c874288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simplifying:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ac67462163466c9ae2ba05310101a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skeletonizing:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeletonized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0843d51a134e1aafef4ae1f53d978c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Healing:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c7832cbaca489fa90d0cd4967a1823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pruning:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 4\n",
      "Starting chunk 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e20e009cb724484b8bcbaeb09be74c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simplifying:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeacb8d5b2a49c09667f21d803788ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skeletonizing:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeletonized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fca06ef09fb4294b16c50b4bb90417c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Healing:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac2ebfc2d77429f99745425cb733166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pruning:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 5\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 5\n",
    "start = 4\n",
    "for s in range(start, int(np.ceil(len(missing_cids)/chunk_size))):\n",
    "    chunk = missing_cids[s*chunk_size:(s+1)*chunk_size]\n",
    "    print('Starting chunk', s)\n",
    "    trees, branches = process_chunk(chunk, vol, syn_df)\n",
    "    extra_trees.update(trees)\n",
    "    extra_branches.update(branches)\n",
    "    print('Finished chunk', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_chunks = [0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 9 with id 48656505068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4d9b452018422ab23d41ee4cf1cf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simplifying:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b61d8cdeecb46649e7a24490d6bd8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skeletonizing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeletonized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1196c2fadbc4afb82c1d9d183ba99bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Healing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf80b156a6540428b201cccdbb580bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pruning:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished id 48656505068\n"
     ]
    }
   ],
   "source": [
    "indiv_ids = [x for i in bad_chunks for x in missing_cids[i*chunk_size:(i+1)*chunk_size] ]\n",
    "start = 9\n",
    "for s in range(start, len(indiv_ids)):\n",
    "    iid = indiv_ids[s]\n",
    "    print('Starting at', s, 'with id', iid)\n",
    "    trees, branches = process_chunk([iid], vol, syn_df)\n",
    "    extra_trees.update(trees)\n",
    "    extra_branches.update(branches)\n",
    "    print('Finished id', iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [5131361032, 6644463791, 38613441248, 3425979752]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the extra trees and branches\n",
    "with open('./data/trees3/trees_200.pkl', 'wb') as f:\n",
    "    pickle.dump(extra_trees, f)\n",
    "with open('./data/trees3/branches_200.pkl', 'wb') as f:\n",
    "    pickle.dump(extra_branches, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_ids = []\n",
    "# # remove bad_ids from cell_df\n",
    "# cell_df = cell_df[~cell_df['pt_root_id'].isin(bad_ids)]\n",
    "# cell_df.to_csv('./data/post_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate into one branches and trees dict\n",
    "all_trees = {}\n",
    "all_branches = {}\n",
    "\n",
    "for fname in os.listdir('./data/trees'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        all_trees.update(trees)\n",
    "\n",
    "for fname in os.listdir('./data/trees2'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees2',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        all_trees.update(trees)\n",
    "\n",
    "for fname in os.listdir('./data/trees3'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees3',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        all_trees.update(trees)\n",
    "\n",
    "for fname in os.listdir('./data/trees4'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/trees4',fname), 'rb') as f:\n",
    "            trees = pickle.load(f)\n",
    "        all_trees.update(trees)\n",
    "\n",
    "for fname in os.listdir('./data/branches'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/branches',fname), 'rb') as f:\n",
    "            branches = pickle.load(f)\n",
    "        all_branches.update(branches)\n",
    "\n",
    "for fname in os.listdir('./data/branches2'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/branches2',fname), 'rb') as f:\n",
    "            branches = pickle.load(f)\n",
    "        all_branches.update(branches)\n",
    "\n",
    "for fname in os.listdir('./data/branches3'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/branches3',fname), 'rb') as f:\n",
    "            branches = pickle.load(f)\n",
    "        all_branches.update(branches)\n",
    "\n",
    "for fname in os.listdir('./data/branches4'):\n",
    "    if fname.endswith('.pkl'):\n",
    "        with open(os.path.join('./data/branches4',fname), 'rb') as f:\n",
    "            branches = pickle.load(f)\n",
    "        all_branches.update(branches)\n",
    "\n",
    "with open('./data/all_trees.pkl', 'wb') as f:\n",
    "    pickle.dump(all_trees, f)\n",
    "\n",
    "with open('./data/all_branches.pkl', 'wb') as f:\n",
    "    pickle.dump(all_branches, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total branch count: 1197042\n",
      "Filtered branch count: 23212\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "total_branches = 0\n",
    "for cid in all_branches:\n",
    "    total_branches += len(all_branches[cid])\n",
    "print('Total branch count:', total_branches)\n",
    "# create a filtered version of all_branches\n",
    "\n",
    "filt_branch_ct = 0\n",
    "filt_branches = defaultdict(list)\n",
    "for cid in all_branches:\n",
    "    valid_branches = []\n",
    "    for branch in all_branches[cid]:\n",
    "        if len(branch.cell_id_sequence['collapsed']) >= 3:\n",
    "            valid_branches.append(branch)\n",
    "    if len(valid_branches) > 0:\n",
    "        filt_branches[cid] = valid_branches\n",
    "        filt_branch_ct += len(valid_branches)\n",
    "\n",
    "print('Filtered branch count:', filt_branch_ct)\n",
    "with open('./data/filt_branches.pkl', 'wb') as f:\n",
    "    pickle.dump(filt_branches, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input count: 100826\n"
     ]
    }
   ],
   "source": [
    "all_inputs = set()\n",
    "for cid in filt_branches:\n",
    "    for branch in filt_branches[cid]:\n",
    "        all_inputs.update(branch.cell_id_sequence['collapsed'])\n",
    "\n",
    "print('Total input count:', len(all_inputs))\n",
    "\n",
    "# save as a pandas dataframe with list in column 'pt_root_id'\n",
    "all_inputs = list(all_inputs)\n",
    "all_inputs = pd.DataFrame({'pt_root_id': all_inputs})\n",
    "all_inputs.to_csv('./data/pre_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
